#!/usr/bin/env python3
"""
Pool Data Manager - í’€ ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬

The Graph APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  SQLite DBë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
ì¤‘ë³µ ë°©ì§€ ë° ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

Usage:
    # ë°ì´í„° ìˆ˜ì§‘ (DBì— ì €ì¥)
    python pool_data_manager.py fetch --pool WETH/USDT --days 365

    # DB ìƒíƒœ í™•ì¸
    python pool_data_manager.py status

    # CSVë¡œ ë‚´ë³´ë‚´ê¸°
    python pool_data_manager.py export --pool WETH/USDT --output data.csv

    # íŠ¹ì • ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
    python pool_data_manager.py query --pool WETH/USDT --from 2024-01-01 --to 2024-12-31
"""

import sys
import os
import sqlite3
import argparse
import csv
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple, Any

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from dotenv import load_dotenv
load_dotenv()

from uniswap_v3.data.graph_client import GraphClient, GraphClientError
from uniswap_v3.constants import CHAIN_IDS


# ============================================================================
# Pool Registry
# ============================================================================

POOL_REGISTRY = {
    "ethereum": {
        "WETH/USDC": {
            "id": "0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8",
            "token0": {"symbol": "USDC", "decimals": 6},
            "token1": {"symbol": "WETH", "decimals": 18},
            "fee_tier": 3000,
            "base_token": "WETH",
        },
        "WETH/USDC-0.05": {
            "id": "0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640",
            "token0": {"symbol": "USDC", "decimals": 6},
            "token1": {"symbol": "WETH", "decimals": 18},
            "fee_tier": 500,
            "base_token": "WETH",
        },
        "WETH/USDT": {
            "id": "0x4e68ccd3e89f51c3074ca5072bbac773960dfa36",
            "token0": {"symbol": "WETH", "decimals": 18},
            "token1": {"symbol": "USDT", "decimals": 6},
            "fee_tier": 3000,
            "base_token": "WETH",
        },
        "WBTC/WETH": {
            "id": "0xcbcdf9626bc03e24f779434178a73a0b4bad62ed",
            "token0": {"symbol": "WBTC", "decimals": 8},
            "token1": {"symbol": "WETH", "decimals": 18},
            "fee_tier": 3000,
            "base_token": "WBTC",
        },
        "WBTC/USDC": {
            "id": "0x99ac8ca7087fa4a2a1fb6357269965a2014abc35",
            "token0": {"symbol": "WBTC", "decimals": 8},
            "token1": {"symbol": "USDC", "decimals": 6},
            "fee_tier": 3000,
            "base_token": "WBTC",
        },
    },
    "polygon": {
        "WETH/USDC": {
            "id": "0x45dda9cb7c25131df268515131f647d726f50608",
            "token0": {"symbol": "WETH", "decimals": 18},
            "token1": {"symbol": "USDC", "decimals": 6},
            "fee_tier": 500,
            "base_token": "WETH",
        },
    },
    "arbitrum": {
        "WETH/USDC": {
            "id": "0xc31e54c7a869b9fcbecc14363cf510d1c41fa443",
            "token0": {"symbol": "WETH", "decimals": 18},
            "token1": {"symbol": "USDC", "decimals": 6},
            "fee_tier": 500,
            "base_token": "WETH",
        },
    },
    "optimism": {
        "WETH/USDC": {
            "id": "0x85149247691df622eaf1a8bd0cafd40bc45154a9",
            "token0": {"symbol": "WETH", "decimals": 18},
            "token1": {"symbol": "USDC", "decimals": 6},
            "fee_tier": 500,
            "base_token": "WETH",
        },
    },
}


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class PoolConfig:
    """í’€ ì„¤ì •"""
    name: str
    chain: str
    pool_id: str
    token0_symbol: str
    token0_decimals: int
    token1_symbol: str
    token1_decimals: int
    fee_tier: int
    base_token: str

    @property
    def invert_price(self) -> bool:
        """ê°€ê²©ì„ ë°˜ì „í•´ì•¼ í•˜ëŠ”ì§€ (base_tokenì´ token1ì¸ ê²½ìš°)"""
        return self.base_token == self.token1_symbol


def get_pool_config(pool_name: str, chain: str = "ethereum") -> Optional[PoolConfig]:
    """í’€ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    chain_pools = POOL_REGISTRY.get(chain, {})
    pool_data = chain_pools.get(pool_name)

    if not pool_data:
        return None

    return PoolConfig(
        name=pool_name,
        chain=chain,
        pool_id=pool_data["id"],
        token0_symbol=pool_data["token0"]["symbol"],
        token0_decimals=pool_data["token0"]["decimals"],
        token1_symbol=pool_data["token1"]["symbol"],
        token1_decimals=pool_data["token1"]["decimals"],
        fee_tier=pool_data["fee_tier"],
        base_token=pool_data["base_token"],
    )


# ============================================================================
# Pool Data Database
# ============================================================================

class PoolDataDB:
    """í’€ ë°ì´í„° SQLite ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"""

    DEFAULT_DB_PATH = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        'data',
        'pool_data.db'
    )

    def __init__(self, db_path: str = None):
        self.db_path = db_path or self.DEFAULT_DB_PATH

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

        self._init_db()

    def _init_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # í’€ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS pools (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pool_id TEXT NOT NULL,
                    chain TEXT NOT NULL,
                    name TEXT NOT NULL,
                    token0_symbol TEXT,
                    token0_decimals INTEGER,
                    token1_symbol TEXT,
                    token1_decimals INTEGER,
                    fee_tier INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(pool_id, chain)
                )
            ''')

            # ì‹œê°„ë³„ ë°ì´í„° í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS pool_hour_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pool_id TEXT NOT NULL,
                    chain TEXT NOT NULL,
                    period_start_unix INTEGER NOT NULL,
                    tick INTEGER,
                    liquidity TEXT,
                    sqrt_price TEXT,
                    high REAL,
                    low REAL,
                    close REAL,
                    fee_growth_global_0_x128 TEXT,
                    fee_growth_global_1_x128 TEXT,
                    token0_decimals INTEGER,
                    token1_decimals INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(pool_id, chain, period_start_unix)
                )
            ''')

            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_pool_hour_data_lookup
                ON pool_hour_data(pool_id, chain, period_start_unix)
            ''')

            conn.commit()

    def save_pool_metadata(self, pool_config: PoolConfig) -> int:
        """í’€ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            cursor.execute('''
                INSERT OR IGNORE INTO pools
                (pool_id, chain, name, token0_symbol, token0_decimals,
                 token1_symbol, token1_decimals, fee_tier)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                pool_config.pool_id,
                pool_config.chain,
                pool_config.name,
                pool_config.token0_symbol,
                pool_config.token0_decimals,
                pool_config.token1_symbol,
                pool_config.token1_decimals,
                pool_config.fee_tier,
            ))

            conn.commit()
            return cursor.lastrowid

    def save_hour_data(self, pool_config: PoolConfig, hour_datas: List[Any]) -> Tuple[int, int]:
        """
        ì‹œê°„ë³„ ë°ì´í„° ì €ì¥ (ì¤‘ë³µ ë¬´ì‹œ)

        Returns:
            (inserted_count, skipped_count)
        """
        if not hour_datas:
            return 0, 0

        inserted = 0
        skipped = 0

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            for hd in hour_datas:
                try:
                    cursor.execute('''
                        INSERT INTO pool_hour_data
                        (pool_id, chain, period_start_unix, tick, liquidity, sqrt_price,
                         high, low, close, fee_growth_global_0_x128, fee_growth_global_1_x128,
                         token0_decimals, token1_decimals)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        pool_config.pool_id,
                        pool_config.chain,
                        hd.period_start_unix,
                        hd.tick,
                        str(hd.liquidity),
                        str(hd.sqrt_price),
                        hd.high,
                        hd.low,
                        hd.close,
                        str(hd.fee_growth_global_0_x128),
                        str(hd.fee_growth_global_1_x128),
                        hd.token0_decimals,
                        hd.token1_decimals,
                    ))
                    inserted += 1
                except sqlite3.IntegrityError:
                    # ì¤‘ë³µ ë°ì´í„° - UNIQUE ì œì•½ ì¡°ê±´ ìœ„ë°˜
                    skipped += 1

            conn.commit()

        return inserted, skipped

    def get_hour_data(
        self,
        pool_id: str,
        chain: str,
        from_timestamp: int,
        to_timestamp: int
    ) -> List[Dict]:
        """ì‹œê°„ë³„ ë°ì´í„° ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute('''
                SELECT * FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
                AND period_start_unix >= ? AND period_start_unix <= ?
                ORDER BY period_start_unix ASC
            ''', (pool_id, chain, from_timestamp, to_timestamp))

            return [dict(row) for row in cursor.fetchall()]

    def get_data_range(self, pool_id: str, chain: str) -> Optional[Tuple[int, int, int]]:
        """
        ì €ì¥ëœ ë°ì´í„° ë²”ìœ„ ì¡°íšŒ

        Returns:
            (min_timestamp, max_timestamp, total_count) or None
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            cursor.execute('''
                SELECT
                    MIN(period_start_unix) as min_ts,
                    MAX(period_start_unix) as max_ts,
                    COUNT(*) as total
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
            ''', (pool_id, chain))

            row = cursor.fetchone()
            if row and row[0]:
                return row[0], row[1], row[2]
            return None

    def get_all_pools(self) -> List[Dict]:
        """ì €ì¥ëœ ëª¨ë“  í’€ ëª©ë¡"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute('''
                SELECT
                    p.*,
                    MIN(d.period_start_unix) as data_from,
                    MAX(d.period_start_unix) as data_to,
                    COUNT(d.id) as data_count
                FROM pools p
                LEFT JOIN pool_hour_data d ON p.pool_id = d.pool_id AND p.chain = d.chain
                GROUP BY p.id
            ''')

            return [dict(row) for row in cursor.fetchall()]

    def print_status(self):
        """DB ìƒíƒœ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print("Pool Data Database Status")
        print("=" * 70)
        print(f"Database: {self.db_path}")

        pools = self.get_all_pools()

        if not pools:
            print("\në°ì´í„° ì—†ìŒ")
            return

        print(f"\nì´ {len(pools)}ê°œ í’€:\n")
        print(f"{'Pool':<20} {'Chain':<12} {'From':<12} {'To':<12} {'Records':>10}")
        print("-" * 70)

        for p in pools:
            from_date = datetime.fromtimestamp(p['data_from']).strftime('%Y-%m-%d') if p['data_from'] else 'N/A'
            to_date = datetime.fromtimestamp(p['data_to']).strftime('%Y-%m-%d') if p['data_to'] else 'N/A'
            print(f"{p['name']:<20} {p['chain']:<12} {from_date:<12} {to_date:<12} {p['data_count']:>10,}")

        print("=" * 70)

    def export_to_csv(self, pool_id: str, chain: str, output_path: str,
                      from_timestamp: int = None, to_timestamp: int = None):
        """CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            query = '''
                SELECT * FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
            '''
            params = [pool_id, chain]

            if from_timestamp:
                query += ' AND period_start_unix >= ?'
                params.append(from_timestamp)

            if to_timestamp:
                query += ' AND period_start_unix <= ?'
                params.append(to_timestamp)

            query += ' ORDER BY period_start_unix ASC'

            cursor.execute(query, params)
            rows = cursor.fetchall()

            if not rows:
                print("ë‚´ë³´ë‚¼ ë°ì´í„° ì—†ìŒ")
                return

            fieldnames = rows[0].keys()

            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                for row in rows:
                    writer.writerow(dict(row))

            print(f"âœ… CSV ì €ì¥: {output_path} ({len(rows)}ê°œ ë ˆì½”ë“œ)")

    def check_integrity(self, pool_id: str, chain: str) -> Dict[str, Any]:
        """
        ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬

        Returns:
            ê²€ì‚¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            'pool_id': pool_id,
            'chain': chain,
            'total_records': 0,
            'date_range': None,
            'expected_hours': 0,
            'missing_hours': 0,
            'missing_pct': 0.0,
            'duplicates': 0,
            'null_ticks': 0,
            'null_fee_growth': 0,
            'tick_range': None,
            'gaps': [],  # 24ì‹œê°„ ì´ìƒ ê°­ ëª©ë¡
            'issues': [],
            'is_valid': True,
        }

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # 1. ì´ ë ˆì½”ë“œ ìˆ˜ ë° ë‚ ì§œ ë²”ìœ„
            cursor.execute('''
                SELECT COUNT(*), MIN(period_start_unix), MAX(period_start_unix)
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
            ''', (pool_id, chain))

            row = cursor.fetchone()
            if not row or not row[1]:
                result['issues'].append("ë°ì´í„° ì—†ìŒ")
                result['is_valid'] = False
                return result

            result['total_records'] = row[0]
            min_ts, max_ts = row[1], row[2]
            result['date_range'] = {
                'from': datetime.fromtimestamp(min_ts).isoformat(),
                'to': datetime.fromtimestamp(max_ts).isoformat(),
            }

            # 2. ì˜ˆìƒ ì‹œê°„ ìˆ˜ ê³„ì‚° (1ì‹œê°„ = 3600ì´ˆ)
            expected_hours = ((max_ts - min_ts) // 3600) + 1
            result['expected_hours'] = expected_hours
            result['missing_hours'] = expected_hours - result['total_records']
            result['missing_pct'] = (result['missing_hours'] / expected_hours) * 100 if expected_hours > 0 else 0

            # 3. ì¤‘ë³µ ê²€ì‚¬
            cursor.execute('''
                SELECT period_start_unix, COUNT(*) as cnt
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
                GROUP BY period_start_unix
                HAVING cnt > 1
            ''', (pool_id, chain))

            duplicates = cursor.fetchall()
            result['duplicates'] = len(duplicates)
            if duplicates:
                result['issues'].append(f"ì¤‘ë³µ íƒ€ì„ìŠ¤íƒ¬í”„ {len(duplicates)}ê°œ ë°œê²¬")
                result['is_valid'] = False

            # 4. NULL ê°’ ê²€ì‚¬
            cursor.execute('''
                SELECT
                    SUM(CASE WHEN tick IS NULL THEN 1 ELSE 0 END) as null_ticks,
                    SUM(CASE WHEN fee_growth_global_0_x128 IS NULL OR fee_growth_global_0_x128 = '' THEN 1 ELSE 0 END) as null_fg
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
            ''', (pool_id, chain))

            null_row = cursor.fetchone()
            result['null_ticks'] = null_row[0] or 0
            result['null_fee_growth'] = null_row[1] or 0

            if result['null_ticks'] > 0:
                result['issues'].append(f"NULL tick ê°’ {result['null_ticks']}ê°œ")

            # 5. tick ë²”ìœ„ ê²€ì‚¬
            cursor.execute('''
                SELECT MIN(tick), MAX(tick)
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ? AND tick IS NOT NULL
            ''', (pool_id, chain))

            tick_row = cursor.fetchone()
            if tick_row[0] is not None:
                result['tick_range'] = {'min': tick_row[0], 'max': tick_row[1]}

            # 6. í° ê°­ ì°¾ê¸° (24ì‹œê°„ ì´ìƒ)
            cursor.execute('''
                SELECT period_start_unix
                FROM pool_hour_data
                WHERE pool_id = ? AND chain = ?
                ORDER BY period_start_unix ASC
            ''', (pool_id, chain))

            timestamps = [row[0] for row in cursor.fetchall()]
            gaps = []
            for i in range(1, len(timestamps)):
                gap_hours = (timestamps[i] - timestamps[i-1]) / 3600
                if gap_hours > 24:
                    gaps.append({
                        'from': datetime.fromtimestamp(timestamps[i-1]).isoformat(),
                        'to': datetime.fromtimestamp(timestamps[i]).isoformat(),
                        'hours': int(gap_hours),
                    })

            result['gaps'] = gaps[:10]  # ìµœëŒ€ 10ê°œë§Œ
            if len(gaps) > 10:
                result['issues'].append(f"24ì‹œê°„+ ê°­ {len(gaps)}ê°œ ë°œê²¬ (ìƒìœ„ 10ê°œë§Œ í‘œì‹œ)")

            # 7. ìµœì¢… ìœ íš¨ì„± íŒë‹¨
            if result['missing_pct'] > 20:
                result['issues'].append(f"ëˆ„ë½ìœ¨ {result['missing_pct']:.1f}% (20% ì´ˆê³¼)")
                result['is_valid'] = False

        return result

    def print_integrity_report(self, pool_id: str, chain: str):
        """ë¬´ê²°ì„± ê²€ì‚¬ ë³´ê³ ì„œ ì¶œë ¥"""
        result = self.check_integrity(pool_id, chain)

        print("\n" + "=" * 70)
        print("ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ ë³´ê³ ì„œ")
        print("=" * 70)
        print(f"Pool ID: {result['pool_id']}")
        print(f"Chain: {result['chain']}")

        if not result['date_range']:
            print("\nâŒ ë°ì´í„° ì—†ìŒ")
            return result

        print(f"\nğŸ“… ë°ì´í„° ë²”ìœ„:")
        print(f"   {result['date_range']['from']} ~ {result['date_range']['to']}")

        print(f"\nğŸ“Š ë ˆì½”ë“œ í†µê³„:")
        print(f"   ì´ ë ˆì½”ë“œ: {result['total_records']:,}ê°œ")
        print(f"   ì˜ˆìƒ ì‹œê°„: {result['expected_hours']:,}ì‹œê°„")
        print(f"   ëˆ„ë½ ì‹œê°„: {result['missing_hours']:,}ì‹œê°„ ({result['missing_pct']:.2f}%)")

        print(f"\nğŸ” ë¬´ê²°ì„± ê²€ì‚¬:")
        print(f"   ì¤‘ë³µ: {result['duplicates']}ê°œ")
        print(f"   NULL tick: {result['null_ticks']}ê°œ")
        print(f"   NULL fee_growth: {result['null_fee_growth']}ê°œ")

        if result['tick_range']:
            print(f"\nğŸ“ˆ Tick ë²”ìœ„:")
            print(f"   Min: {result['tick_range']['min']}")
            print(f"   Max: {result['tick_range']['max']}")

        if result['gaps']:
            print(f"\nâš ï¸  í° ê°­ (24ì‹œê°„+):")
            for gap in result['gaps']:
                print(f"   {gap['from']} ~ {gap['to']} ({gap['hours']}ì‹œê°„)")

        print("\n" + "-" * 70)
        if result['is_valid']:
            print("âœ… ë¬´ê²°ì„± ê²€ì‚¬ í†µê³¼")
        else:
            print("âŒ ë¬´ê²°ì„± ë¬¸ì œ ë°œê²¬:")
            for issue in result['issues']:
                print(f"   - {issue}")

        print("=" * 70)

        return result


# ============================================================================
# Data Fetcher
# ============================================================================

class PoolDataFetcher:
    """í’€ ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, db: PoolDataDB = None, verbose: bool = True):
        self.db = db or PoolDataDB()
        self.verbose = verbose
        self._clients: Dict[str, GraphClient] = {}

    def _get_client(self, chain: str) -> GraphClient:
        """ì²´ì¸ë³„ í´ë¼ì´ì–¸íŠ¸ (ìºì‹±)"""
        if chain not in self._clients:
            self._clients[chain] = GraphClient(chain=chain)
        return self._clients[chain]

    def _log(self, msg: str):
        if self.verbose:
            print(msg)

    def fetch_and_save(
        self,
        pool_config: PoolConfig,
        days: int = 365,
        end_date: datetime = None
    ) -> Tuple[int, int]:
        """
        ë°ì´í„° ìˆ˜ì§‘ ë° DB ì €ì¥

        Returns:
            (inserted_count, skipped_count)
        """
        end_dt = end_date or datetime.now()
        start_dt = end_dt - timedelta(days=days)

        from_ts = int(start_dt.timestamp())
        to_ts = int(end_dt.timestamp())

        self._log(f"\n{'='*60}")
        self._log(f"í’€: {pool_config.name} ({pool_config.chain})")
        self._log(f"ê¸°ê°„: {start_dt.strftime('%Y-%m-%d')} ~ {end_dt.strftime('%Y-%m-%d')} ({days}ì¼)")
        self._log(f"{'='*60}")

        # ê¸°ì¡´ ë°ì´í„° ë²”ìœ„ í™•ì¸
        existing_range = self.db.get_data_range(pool_config.pool_id, pool_config.chain)
        if existing_range:
            existing_from = datetime.fromtimestamp(existing_range[0])
            existing_to = datetime.fromtimestamp(existing_range[1])
            self._log(f"ê¸°ì¡´ ë°ì´í„°: {existing_from.strftime('%Y-%m-%d')} ~ {existing_to.strftime('%Y-%m-%d')} ({existing_range[2]:,}ê°œ)")

        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try:
            client = self._get_client(pool_config.chain)
            self._log(f"\nThe Graph APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

            hour_datas = client.get_pool_hour_datas_paginated(
                pool_config.pool_id, from_ts, to_ts
            )
            hour_datas.sort(key=lambda x: x.period_start_unix)

            self._log(f"ê°€ì ¸ì˜¨ ë°ì´í„°: {len(hour_datas)}ê°œ")

        except GraphClientError as e:
            self._log(f"âŒ API ì˜¤ë¥˜: {e}")
            return 0, 0

        if not hour_datas:
            self._log("ë°ì´í„° ì—†ìŒ")
            return 0, 0

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self.db.save_pool_metadata(pool_config)

        # ì‹œê°„ë³„ ë°ì´í„° ì €ì¥
        inserted, skipped = self.db.save_hour_data(pool_config, hour_datas)

        self._log(f"\nâœ… ì €ì¥ ì™„ë£Œ:")
        self._log(f"   - ìƒˆë¡œ ì¶”ê°€: {inserted:,}ê°œ")
        self._log(f"   - ì¤‘ë³µ ìŠ¤í‚µ: {skipped:,}ê°œ")

        return inserted, skipped

    def fetch_multiple(
        self,
        pools: List[Tuple[str, str]],  # [(pool_name, chain), ...]
        days: int = 365,
        end_date: datetime = None
    ) -> Dict[str, Tuple[int, int]]:
        """ì—¬ëŸ¬ í’€ ë°ì´í„° ìˆ˜ì§‘"""
        results = {}

        for pool_name, chain in pools:
            pool_config = get_pool_config(pool_name, chain)
            if not pool_config:
                self._log(f"âš ï¸  í’€ ì—†ìŒ: {pool_name} ({chain})")
                continue

            inserted, skipped = self.fetch_and_save(pool_config, days, end_date)
            results[f"{pool_name}_{chain}"] = (inserted, skipped)

        return results


# ============================================================================
# CLI
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='Pool Data Manager - í’€ ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ë°ì´í„° ìˆ˜ì§‘
  python pool_data_manager.py fetch --pool WETH/USDT --days 365

  # ì—¬ëŸ¬ í’€ ìˆ˜ì§‘
  python pool_data_manager.py fetch --pool WETH/USDT,WETH/USDC --days 365

  # DB ìƒíƒœ í™•ì¸
  python pool_data_manager.py status

  # ë¬´ê²°ì„± ê²€ì‚¬
  python pool_data_manager.py check --pool WETH/USDT

  # CSV ë‚´ë³´ë‚´ê¸°
  python pool_data_manager.py export --pool WETH/USDT --output data.csv

  # ì‚¬ìš© ê°€ëŠ¥í•œ í’€ ëª©ë¡
  python pool_data_manager.py list-pools
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')

    # fetch ëª…ë ¹
    fetch_parser = subparsers.add_parser('fetch', help='ë°ì´í„° ìˆ˜ì§‘')
    fetch_parser.add_argument('--pool', type=str, required=True,
                              help='í’€ ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„). ì˜ˆ: WETH/USDT,WETH/USDC')
    fetch_parser.add_argument('--chain', type=str, default='ethereum',
                              choices=list(CHAIN_IDS.keys()),
                              help='ì²´ì¸ (default: ethereum)')
    fetch_parser.add_argument('--days', type=int, default=365,
                              help='ìˆ˜ì§‘ ê¸°ê°„ (ì¼, default: 365)')

    # status ëª…ë ¹
    subparsers.add_parser('status', help='DB ìƒíƒœ í™•ì¸')

    # export ëª…ë ¹
    export_parser = subparsers.add_parser('export', help='CSV ë‚´ë³´ë‚´ê¸°')
    export_parser.add_argument('--pool', type=str, required=True,
                               help='í’€ ì´ë¦„')
    export_parser.add_argument('--chain', type=str, default='ethereum',
                               help='ì²´ì¸')
    export_parser.add_argument('--output', type=str, required=True,
                               help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    export_parser.add_argument('--from', dest='from_date', type=str,
                               help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    export_parser.add_argument('--to', dest='to_date', type=str,
                               help='ì¢…ë£Œì¼ (YYYY-MM-DD)')

    # list-pools ëª…ë ¹
    subparsers.add_parser('list-pools', help='ì‚¬ìš© ê°€ëŠ¥í•œ í’€ ëª©ë¡')

    # check ëª…ë ¹ (ë¬´ê²°ì„± ê²€ì‚¬)
    check_parser = subparsers.add_parser('check', help='ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬')
    check_parser.add_argument('--pool', type=str, required=True,
                              help='í’€ ì´ë¦„')
    check_parser.add_argument('--chain', type=str, default='ethereum',
                              help='ì²´ì¸')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    db = PoolDataDB()

    if args.command == 'status':
        db.print_status()

    elif args.command == 'list-pools':
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í’€ ëª©ë¡:")
        print("=" * 50)
        for chain, pools in POOL_REGISTRY.items():
            print(f"\n{chain.upper()}:")
            for pool_name in pools:
                print(f"  - {pool_name}")
        print()

    elif args.command == 'fetch':
        pool_names = [p.strip() for p in args.pool.split(',')]
        pools = [(name, args.chain) for name in pool_names]

        fetcher = PoolDataFetcher(db=db)
        results = fetcher.fetch_multiple(pools, days=args.days)

        print("\n" + "=" * 50)
        print("ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
        for key, (inserted, skipped) in results.items():
            print(f"  {key}: +{inserted:,} ìƒˆë¡œ ì¶”ê°€, {skipped:,} ì¤‘ë³µ ìŠ¤í‚µ")
        print("=" * 50)

    elif args.command == 'export':
        pool_config = get_pool_config(args.pool, args.chain)
        if not pool_config:
            print(f"âŒ í’€ ì—†ìŒ: {args.pool} ({args.chain})")
            return

        from_ts = None
        to_ts = None

        if args.from_date:
            from_ts = int(datetime.strptime(args.from_date, '%Y-%m-%d').timestamp())
        if args.to_date:
            to_ts = int(datetime.strptime(args.to_date, '%Y-%m-%d').timestamp())

        db.export_to_csv(
            pool_config.pool_id,
            pool_config.chain,
            args.output,
            from_ts,
            to_ts
        )

    elif args.command == 'check':
        pool_config = get_pool_config(args.pool, args.chain)
        if not pool_config:
            print(f"âŒ í’€ ì—†ìŒ: {args.pool} ({args.chain})")
            return

        db.print_integrity_report(pool_config.pool_id, pool_config.chain)


if __name__ == "__main__":
    main()
